{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "FinalColorization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUGVIFM6u18t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lg0Vc8CLe8x_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20310829-e51f-478f-f59d-5b189c359c12"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1ytwao3ExAj"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGOEp_n0A7D4"
      },
      "source": [
        " \n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from keras.layers import Conv2D, UpSampling2D\n",
        "from skimage.color import rgb2lab, lab2rgb\n",
        "from keras.applications.inception_resnet_v2 import preprocess_input\n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "from keras.layers import Input, Reshape, concatenate\n",
        "from keras.models import Model\n",
        "from keras.layers.core import RepeatVector\n",
        "from skimage.transform import resize\n",
        " \n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFL52YFyB4y2"
      },
      "source": [
        "# Get images\n",
        "X = []\n",
        "#path =\"/content/drive/MyDrive/colorizing/Dataset/\"\n",
        "path =\"val2017/\"\n",
        "i = 0\n",
        "for filename in os.listdir(path):\n",
        "    i+=1\n",
        "    img = cv2.imread(path+filename)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(img,(256,256))\n",
        "    X.append(img)\n",
        "    if i == 500 :\n",
        "      break\n",
        "\n",
        "\n",
        "X = np.array(X, dtype=float)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdmZ6zWRBpKJ",
        "outputId": "e41d4a6d-badd-4a71-9b46-b171a0aeceaf"
      },
      "source": [
        "print(X.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(500, 256, 256, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EllKsK9b42QB"
      },
      "source": [
        "Xtrain = rgb2lab(1.0/255*X)[:,:,:,0]\n",
        "Ytrain = rgb2lab(1.0/255*X)[:,:,:,1:]\n",
        "Xtrain = Xtrain = Xtrain.reshape(Xtrain.shape+(1,))\n",
        "Ytrain /= 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeUWyHhhCTAK",
        "outputId": "76dbf269-10b1-4114-9f26-6a6a4d4c34a6"
      },
      "source": [
        "print(Xtrain.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(500, 256, 256, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4AcPL7WFJ2P"
      },
      "source": [
        "loss curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qV2qIWkEVcsa"
      },
      "source": [
        "class LossHistory(keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.losses = []\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        self.losses.append(logs.get('loss'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_YktX6LFobD"
      },
      "source": [
        "**Train model **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNhmqjjiB878",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8101283-6137-43fe-bea3-e4f4966d79c7"
      },
      "source": [
        "#Load weights\n",
        "inception = tf.keras.applications.InceptionResNetV2(include_top=True, weights='imagenet')\n",
        "\n",
        "\n",
        "#Encoder\n",
        "encoder_input = Input(shape=(256, 256, 1,))\n",
        "encoder_output = Conv2D(64, (3,3), activation='relu', padding='same', strides=2)(encoder_input)\n",
        "encoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(encoder_output)\n",
        "encoder_output = Conv2D(128, (3,3), activation='relu', padding='same', strides=2)(encoder_output)\n",
        "encoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(encoder_output)\n",
        "encoder_output = Conv2D(256, (3,3), activation='relu', padding='same', strides=2)(encoder_output)\n",
        "encoder_output = Conv2D(512, (3,3), activation='relu', padding='same')(encoder_output)\n",
        "encoder_output = Conv2D(512, (3,3), activation='relu', padding='same')(encoder_output)\n",
        "encoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(encoder_output)\n",
        "\n",
        "#Fusion\n",
        "embed_input = Input(shape=(1000,))\n",
        "fusion_output = RepeatVector(32 * 32)(embed_input) \n",
        "fusion_output = Reshape(([32, 32, 1000]))(fusion_output)\n",
        "fusion_output = concatenate([encoder_output, fusion_output], axis=3) \n",
        "fusion_output = Conv2D(256, (1, 1), activation='relu', padding='same')(fusion_output) \n",
        "\n",
        "#Decoder\n",
        "decoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(fusion_output)\n",
        "\n",
        "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "\n",
        "decoder_output = Conv2D(64, (3,3), activation='relu', padding='same')(decoder_output)\n",
        "\n",
        "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "\n",
        "decoder_output = Conv2D(32, (3,3), activation='relu', padding='same')(decoder_output)\n",
        "decoder_output = Conv2D(16, (3,3), activation='relu', padding='same')(decoder_output)\n",
        "decoder_output = Conv2D(2, (3, 3), activation='tanh', padding='same')(decoder_output)\n",
        "\n",
        "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "\n",
        "model = Model(inputs=[encoder_input, embed_input], outputs=decoder_output)\n",
        "        \n",
        "def create_inception_embedding(grayscaled_rgb): # 265 *265 * 1 \n",
        "    grayscaled_rgb_resized = []\n",
        "    for i in grayscaled_rgb:\n",
        "        i = resize(i, (299, 299, 3), mode='constant')\n",
        "        i = lab2rgb(i)\n",
        "        grayscaled_rgb_resized.append(i)\n",
        "    grayscaled_rgb_resized = np.array(grayscaled_rgb_resized)\n",
        "\n",
        "    grayscaled_rgb_resized = preprocess_input(grayscaled_rgb_resized)\n",
        "    #with inception.graph.as_default():\n",
        "\n",
        "    embed = inception.predict(grayscaled_rgb_resized)\n",
        "    \n",
        "    return embed\n",
        "\n",
        "x=[Xtrain, create_inception_embedding(Xtrain)]\n",
        "print(model.summary())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 256, 256, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 128, 128, 64) 640         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 128, 128, 128 73856       conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 64, 64, 128)  147584      conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 64, 64, 256)  295168      conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 32, 32, 256)  590080      conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 32, 32, 512)  1180160     conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 1000)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 32, 32, 512)  2359808     conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector_1 (RepeatVector)  (None, 1024, 1000)   0           input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 32, 32, 256)  1179904     conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 32, 32, 1000) 0           repeat_vector_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 1256) 0           conv2d_21[0][0]                  \n",
            "                                                                 reshape_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 32, 32, 256)  321792      concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 32, 32, 128)  295040      conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 64, 64, 128)  0           conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 64, 64, 64)   73792       up_sampling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 128, 128, 64) 0           conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 128, 128, 32) 18464       up_sampling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 128, 128, 16) 4624        conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 128, 128, 2)  290         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2D)  (None, 256, 256, 2)  0           conv2d_27[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 6,541,202\n",
            "Trainable params: 6,541,202\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNx3sQtpG1xO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f02f43d3-5467-4ca2-e834-6c051800e176"
      },
      "source": [
        "#Train model\n",
        "model.compile(optimizer='adam',loss='mse')\n",
        "#history = LossHistory()\n",
        "\n",
        "model.fit(x=x, y=Ytrain, epochs=10  )\n",
        "\n",
        "#, batch_size=10 ,callbacks=[history]\n",
        "#Save model\n",
        "model.save('/content/drive/MyDrive/colorizing/model.h5')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "16/16 [==============================] - 49s 1s/step - loss: 0.1559\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 10s 651ms/step - loss: 0.0123\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 10s 652ms/step - loss: 0.0129\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 10s 652ms/step - loss: 0.0123\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 10s 650ms/step - loss: 0.0119\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 10s 650ms/step - loss: 0.0129\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 10s 651ms/step - loss: 0.0124\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 10s 653ms/step - loss: 0.0121\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 10s 652ms/step - loss: 0.0122\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 10s 650ms/step - loss: 0.0131\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "id": "hNfpXmhlokSd",
        "outputId": "71a26607-f6a6-4212-e34b-c508fe2c0cc7"
      },
      "source": [
        "results = model.evaluate(x=x, Ytrain, batch_size=128)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-25-6f619016fefd>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    results = model.evaluate(x=x, Ytrain, batch_size=128)\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m positional argument follows keyword argument\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spMG8v-9E-Zc",
        "outputId": "0e6ef2e1-e481-4644-c87a-c8de8987cf5d"
      },
      "source": [
        "print(len(x[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "js0odh-XGnrW"
      },
      "source": [
        "\n",
        "\n",
        "test accurcy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVWahUU2Qtjm"
      },
      "source": [
        "***Pridict***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMz-K4awQzgB",
        "outputId": "e348b81b-c6b0-4dab-b75a-cc67873ed4d6"
      },
      "source": [
        "from keras.models import load_model\n",
        "from skimage.color import rgb2lab, lab2rgb\n",
        "from keras.applications.inception_resnet_v2 import preprocess_input\n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "from skimage.transform import resize\n",
        "from skimage.io import imsave\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "#Load model\n",
        "model = load_model('/content/drive/MyDrive/colorizing/modelFamily.h5')\n",
        "#Load weights\n",
        "inception = tf.keras.applications.InceptionResNetV2(include_top=True, weights='imagenet')\n",
        "\n",
        "def create_inception_embedding(grayscaled_rgb):\n",
        "    grayscaled_rgb_resized = []\n",
        "    for i in grayscaled_rgb:\n",
        "        i = resize(i, (299, 299, 3), mode='constant')\n",
        "        i = lab2rgb(i)\n",
        "        grayscaled_rgb_resized.append(i)\n",
        "    grayscaled_rgb_resized = np.array(grayscaled_rgb_resized)\n",
        "    grayscaled_rgb_resized = preprocess_input(grayscaled_rgb_resized)\n",
        "    embed = inception.predict(grayscaled_rgb_resized)\n",
        "    return embed\n",
        "\n",
        "color_me = []\n",
        "path =\"/content/drive/MyDrive/colorizing/Test/People/\"\n",
        "for filename in os.listdir(path):\n",
        "    img = cv2.imread(path+filename)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(img,(256,256))\n",
        "    color_me.append(img)\n",
        "color_me = np.array(color_me, dtype=float)\n",
        "color_me = rgb2lab(1.0/255*color_me)[:,:,:,0]\n",
        "color_me = color_me.reshape(color_me.shape+(1,))\n",
        "\n",
        "# Test model\n",
        "output = model.predict([color_me, create_inception_embedding(color_me)])\n",
        "output *= 128\n",
        "\n",
        "# Output colorizations\n",
        "for i in range(len(output)):\n",
        "    cur = np.zeros((256, 256, 3))\n",
        "    cur[:,:,0] = color_me[i][:,:,0]\n",
        "    cur[:,:,1:] = output[i]\n",
        "    imsave(\"img\"+str(i)+\".png\", lab2rgb(cur))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OfJK3cxGm2v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8676b23e-7150-4ba0-ddf2-7bdcecb1c8b0"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from skimage.color import rgb2lab, lab2rgb, rgb2gray, xyz2lab\n",
        "from skimage.io import imsave\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "def PSNR(original , colored ):\n",
        "\tmse = np.mean((original - colored)**2)\n",
        "\tprint(mse.shape)\n",
        "\tif(mse == 0 ): \n",
        "\t\treturn 100 \n",
        "\tmax_pixel=255.0\n",
        "\tpsnr = 20 *np.log10(max_pixel/ np.sqrt(mse)) \n",
        "\treturn psnr\n",
        "\n",
        "ORIGINAL = img_to_array(load_img('/content/drive/MyDrive/colorizing/Dataset/colour.jpg'))\n",
        "ORIGINAL = np.array(ORIGINAL, dtype=float)\n",
        "ORIGINAL = cv2.resize(ORIGINAL,(256,256))\n",
        "\n",
        "COLOR = img_to_array(load_img('img3.png'))\n",
        "COLOR = np.array(COLOR, dtype=float)\n",
        "\n",
        "psnr =PSNR(ORIGINAL,COLOR)\n",
        "\n",
        "print(psnr) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "()\n",
            "9.256170863109215\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "GFEl5QAaVIEv",
        "outputId": "084c95cf-793f-4551-91b1-ad92dfd08e05"
      },
      "source": [
        "\n",
        "print(history.losses)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-2c38323747fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPDjWhR7bLi9"
      },
      "source": [
        "loss curve\n"
      ]
    }
  ]
}